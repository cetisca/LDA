{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 100 documents and 4893 words in total!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, save_npz\n",
    "#from sklearn.metrics.pairwise import pairwise_distances\n",
    "import os\n",
    "\n",
    "FolderToParse = \"BoW_100random/\"#\"BagsOfWords/\"\n",
    "DocList = []\n",
    "for document in os.listdir( FolderToParse ):\n",
    "    # load documents\n",
    "    FileToLoad = FolderToParse + document\n",
    "    f = open(FileToLoad,'rb')\n",
    "    words = f.read().decode('ascii', 'ignore')\n",
    "    f.close()\n",
    "    words = words.split()\n",
    "    DocList.append(words)\n",
    "X_words = DocList#[:100]\n",
    "\n",
    "corpus=np.unique(np.concatenate(X_words))\n",
    "N_D = len(X_words) # number of documents\n",
    "N_V = len(corpus)  # number of vocabulary - all available words\n",
    "N_K = 10 # set the number of topics\n",
    "print(\"We have {0} documents and {1} words in total!\".format(N_D, N_V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Term-Doc matrix is 2.57% dense.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "# initialize term - document matrix\n",
    "#TDM = csr_matrix((N_V,N_D))\n",
    "TDM = np.zeros((N_V,N_D)) # we start by a full matrix and then transform it\n",
    "#TDM = [] \n",
    "t0 = time()\n",
    "# create doc-word list of lists\n",
    "for doc in range(N_D):\n",
    "    temp = np.unique( X_words[doc] ) # get the different words on this document\n",
    "    #temp2 = np.zeros((N_V,1))\n",
    "    for i in range( len(temp) ):\n",
    "        word = temp[i] \n",
    "        count = len([ x for x in X_words[doc] if x == word])\n",
    "        # we must get the index of this word in the (total) corpus\n",
    "        TDM[ np.where(corpus == word) , doc] = count\n",
    "        #temp2[ np.where(corpus == word) ] = count\n",
    "    #TDM.append(temp2)\n",
    "    # progress check\n",
    "    if ((doc+1) % 500) == 0 :\n",
    "        print('More than {0} documents have been processed! Rate = {1}'.format(doc+1, (time()-t0)/doc))\n",
    "\n",
    "# sanity check\n",
    "for doc in range(N_D):\n",
    "    if sum(TDM[:,doc])!=len(X_words[doc]):\n",
    "        print(\"Doc-{0} has a problem!\".format(doc))\n",
    "TDM = csr_matrix(TDM)\n",
    "print(\"The Term-Doc matrix is {0:.2f}% dense.\".format(csr_matrix.count_nonzero(TDM)/np.prod(TDM.shape)*100))\n",
    "#print(\"The Term-Doc matrix is {0:.2f}% dense.\".format(np.count_nonzero(TDM)/np.prod(TDM.shape)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE IT\n",
    "# scipy.sparse\n",
    "#scipy.sparse.save_npz('Term_Doc_Matrix_All.npz',TDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Black and white clustering - the number of clusters is N_K\n",
    "# initialize the dictictionary of clusters\n",
    "Clusters = { i:[] for i in range(N_K)}\n",
    "ClustersNames = { i:[] for i in range(N_K)} \n",
    "Labels = []\n",
    "for i in range(len(DocList)):\n",
    "    distr = [ x[1] for x in Pi[i]]\n",
    "    # find the argmax{distr} - ATTENTION: ties ???\n",
    "    label = distr.index(max(distr))\n",
    "    Clusters[label].append(i)\n",
    "    ClustersNames[label].append(Names[i])\n",
    "    Labels.append( label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distances \n",
    "Distances = np.zeros((N_D,N_D))\n",
    "for i in range(N_D):\n",
    "    for j in range(i+1,N_D):\n",
    "        # we use the standard euclidean distance == norm-2 for vectors\n",
    "        Distances[i,j] = np.linalg.norm( csr_matrix.todense(TDM[:,i] - TDM[:,j]),2 ) #GetDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "#from scipy.sparse import save_npz\n",
    "np.save('100New_Doc_Distances.npy',Distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Now compare the distances for different clusters....\n",
    "ClusterDist = np.zeros( (N_K,N_K))\n",
    "for c1 in range(N_K):\n",
    "    if len(Clusters[c1])>0:\n",
    "        for c2 in range(c1,N_K):\n",
    "            #first we compute the intra-cluster distance\n",
    "            if len(Clusters[c2])>0:\n",
    "                ClusterDist[c1,c2] = ComputeDistances(Distances, list(Clusters[c1]), list(Clusters[c2]))\n",
    "\n",
    "def ComputeDistances(D, C1, C2):\n",
    "    \"\"\"\n",
    "        Function that, given two sets of indices C1, C2 and a matrix D with  \n",
    "        distances calculated for every pair, it computes the average distance.\n",
    "    \"\"\"\n",
    "    S=0\n",
    "    for i in range(len(C1)):\n",
    "        for j in range(len(C2)):\n",
    "            S += S + D[ C1[i], C2[j] ]\n",
    "    return S/(len(C1)*len(C2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('Doc_Doc_Distances_All.npz',Distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White-rimmed brush finch\n",
      "White-throated jacamar\n",
      "Willard's sooty boubou\n",
      "Yellow-bellied tit\n",
      "Yellow-eyed starling\n",
      "Black-faced dacnis\n",
      "Black-crowned tchagra\n",
      "Ahanta francolin\n",
      "Black-hooded sierra finch\n",
      "Black-tipped cotinga\n",
      "Blue-black kingfisher\n",
      "Blue-winged teal\n",
      "Brasília tapaculo\n",
      "Brown sicklebill\n",
      "Brush cuckoo\n",
      "Bush blackcap\n",
      "Abbott's babbler\n",
      "Caquetá seedeater\n",
      "Cherry-throated tanager\n",
      "Andaman masked owl\n",
      "Chestnut-hooded laughingthrush\n",
      "Chubut steamer duck\n",
      "Cocoi heron\n",
      "Common ringed plover\n",
      "Crested barbet\n",
      "Cuban gnatcatcher\n",
      "Dieffenbach's rail\n",
      "Dusky-faced tanager\n",
      "Elegant crested tinamou\n",
      "European stonechat\n",
      "Arctic tern\n",
      "Flores green pigeon\n",
      "Franklin's gull\n",
      "Gillett's lark\n",
      "Golden-naped woodpecker\n",
      "Great parrotbill\n",
      "Green racket-tail\n",
      "Grey heron\n",
      "Grey-collared oriole\n",
      "Grey-throated tit-flycatcher\n",
      "Harwood's francolin\n",
      "Australasian gannet\n",
      "Holub's golden weaver\n",
      "Ihering's antwren\n",
      "Jacobin cuckoo\n",
      "Kadavu fantail\n",
      "Labrador duck\n",
      "Lemon-bellied white-eye\n",
      "Line-fronted canastero\n",
      "Long-billed white-eye\n",
      "MacGregor's honeyeater\n",
      "Malayan banded pitta\n",
      "Banded bay cuckoo\n",
      "Marquesan ground dove\n",
      "Melodious babbler\n",
      "Montane nightjar\n",
      "Moustached barbet\n",
      "New Caledonian thicketbird\n",
      "Hen harrier\n",
      "Okarito kiwi\n",
      "Orange-breasted laughingthrush\n",
      "Paddyfield pipit\n",
      "Swallow-tailed cotinga\n",
      "Barred owlet-nightjar\n",
      "Pearly-breasted cuckoo\n",
      "Pied honeyeater\n",
      "Plain-brown woodcreeper\n",
      "Puerto Rican oriole\n",
      "Radde's accentor\n",
      "Red-breasted meadowlark\n",
      "Red-headed parrotfinch\n",
      "Red-winged parrot\n",
      "Rockefeller's sunbird\n",
      "Rufous babbler\n",
      "Grey-banded babbler\n",
      "Rufous-crowned antpitta\n",
      "Rufous-webbed bush tyrant\n",
      "Saddle-billed stork\n",
      "Satin bowerbird\n",
      "Scissor-tailed kite\n",
      "Shining-blue kingfisher\n",
      "Silvery pigeon\n",
      "Small niltava\n",
      "Sooty barbet\n",
      "Spangle-cheeked tanager\n",
      "Black turnstone\n",
      "Spot-throated woodcreeper\n",
      "Saint Lucia black finch\n",
      "Striated babbler\n",
      "Sulawesi scops owl\n",
      "Swee waxbill\n",
      "Tawny-breasted tinamou\n",
      "Ticking doradito\n",
      "Tucumán mountain finch\n",
      "Variable wheatear\n",
      "Violet-throated starfrontlet\n",
      "Black-breasted buttonquail\n",
      "Western capercaillie\n",
      "White-bellied chachalaca\n",
      "White-browed spinetail\n"
     ]
    }
   ],
   "source": [
    "with open('list_of_species.txt', encoding='utf-8', errors='ignore') as f:\n",
    "    Names = f.readlines()\n",
    "Names = [x.strip() for x in Names]\n",
    "Names_100New = []\n",
    "for document in os.listdir( \"BoW_100random/\" ):\n",
    "    temp = Names[ int(document[:-8])-1 ]\n",
    "    #print( temp )\n",
    "    Names_100New.append( temp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.dirichlet?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
