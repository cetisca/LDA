{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 101 documents and 3409 words in total!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "#from sklearn.metrics.pairwise import pairwise_distances\n",
    "import os\n",
    "\n",
    "FolderToParse = \"BagsOfWords/\"\n",
    "DocList = []\n",
    "for document in os.listdir( FolderToParse ):\n",
    "    # load documents\n",
    "    FileToLoad = FolderToParse + document\n",
    "    f = open(FileToLoad,'rb')\n",
    "    words = f.read().decode('ascii', 'ignore')\n",
    "    f.close()\n",
    "    words = words.split()\n",
    "    DocList.append(words)\n",
    "X_words = DocList\n",
    "\n",
    "corpus=np.unique(np.concatenate(X_words),axis=0)\n",
    "N_D = len(X_words) # number of documents\n",
    "N_V = len(corpus)  # number of vocabulary - all available words\n",
    "N_K = 10 # set the number of topics\n",
    "print(\"We have {0} documents and {1} words in total!\".format(N_D, N_V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Term-Doc matrix is 2.57% dense.\n"
     ]
    }
   ],
   "source": [
    "# initialize term - document matrix\n",
    "#TDM = csr_matrix((N_V,N_D))\n",
    "TDM = np.zeros((N_V,N_D)) # we start by a full matrix and then transform it\n",
    "     \n",
    "# create doc-word list of lists\n",
    "for doc in range(N_D):\n",
    "    temp = np.unique( X_words[doc] ) # get the different words on this document\n",
    "    for i in range( len(temp) ):\n",
    "        word = temp[i] \n",
    "        count = len([ x for x in X_words[doc] if x == word])\n",
    "        # we must get the index of this word in the (total) corpus\n",
    "        TDM[ np.where(corpus == word) , doc] = count\n",
    "        \n",
    "# sanity check\n",
    "for doc in range(N_D):\n",
    "    if sum(TDM[:,doc])!=len(X_words[doc]):\n",
    "        print(\"Doc-{0} has a problem!\".format(i))\n",
    "TDM = csr_matrix(TDM)\n",
    "print(\"The Term-Doc matrix is {0:.2f}% dense.\".format(csr_matrix.count_nonzero(TDM)/np.prod(TDM.shape)*100))\n",
    "#print(\"The Term-Doc matrix is {0:.2f}% dense.\".format(np.count_nonzero(TDM)/np.prod(TDM.shape)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-4bf24aa1bd2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc_number\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdoc_length\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_number\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                     \u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_number\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_number\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mdoc_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_number\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_length\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Resample word topic distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Implement LDA\n",
    "# Number matrix (Replacing words in documents with word IDs)\n",
    "N_K = 10 # set the number of topics\n",
    "N_W = N_V\n",
    "X_number = np.copy(X_words)\n",
    "for doc_number in range(X_number.shape[0]):\n",
    "    for doc_length in range(len(X_number[doc_number])):\n",
    "        X_number[doc_number][doc_length]=  np.where(corpus==X_number[doc_number][doc_length])[0][0]\n",
    "        \n",
    "# Dirichlet priors\n",
    "alpha = 1 # Choice of alpha affects document clustering \n",
    "gamma = 1\n",
    "\n",
    "Z = np.copy(X_number)\n",
    "for doc_number in range(Z.shape[0]):\n",
    "    for doc_length in range(len(Z[doc_number])):\n",
    "        Z[doc_number][doc_length]= np.random.randint(N_K)\n",
    "        \n",
    "# Pi := document topic distribution\n",
    "Pi = np.zeros([N_D, N_K])\n",
    "for i in range(N_D):\n",
    "    Pi[i] = np.random.dirichlet(alpha*np.ones(N_K))\n",
    "    \n",
    "# B := word topic distribution\n",
    "B = np.zeros([N_K, N_W])\n",
    "\n",
    "for k in range(N_K):\n",
    "    B[k] = np.random.dirichlet(gamma*np.ones(N_W))\n",
    "    \n",
    "for iterations in range(10):  #Need at least 1000 iterations for Gibbs sampling to work!\n",
    "    \n",
    "    \n",
    "    # Updating Z matrix\n",
    "    for doc_number in range(Z.shape[0]):     \n",
    "        for doc_length in range(len(Z[doc_number])):\n",
    "            \n",
    "             # Calculate params for Z\n",
    "            p_iv = np.exp(np.log(Pi[i]) + np.log(B[:, X_number[doc_number][ doc_length]]))\n",
    "            p_iv /= np.sum(p_iv)\n",
    "\n",
    "             # Resample word topic assignment Z\n",
    "            Z[doc_number][doc_length] = np.random.multinomial(1, p_iv).argmax()\n",
    "     \n",
    "    # Updating Pi   \n",
    "    for i in range(N_D):\n",
    "        m = np.zeros(N_K)\n",
    "\n",
    "        # Gather sufficient statistics\n",
    "        for k in range(N_K):\n",
    "            m[k] = np.sum(Z[i] == k)\n",
    "\n",
    "        # Resample doc topic dist.\n",
    "        Pi[i, :] = np.random.dirichlet(alpha + m)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    #Updating B\n",
    "    \n",
    "    for k in range(N_K):\n",
    "        print(k)\n",
    "        n = np.zeros(N_W)\n",
    "    \n",
    "        #Gather statistics\n",
    "        \n",
    "        for v in range(N_W):\n",
    "            for doc_number in range(Z.shape[0]):\n",
    "                for doc_length in range(len(Z[doc_number])):\n",
    "                    n[v] += (X_number[doc_number][ doc_length]==v) and (Z[doc_number][doc_length] ==k)\n",
    "        \n",
    "        # Resample word topic distribution\n",
    "        \n",
    "        B[k,:] = np.random.dirichlet(gamma+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distances \n",
    "Distances = np.zeros((N_D,N_D))\n",
    "for i in range(N_D):\n",
    "    for j in range(i+1,N_D):\n",
    "        # we use the standard euclidean distance == norm-2 for vectors\n",
    "        Distances[i,j] = np.linalg.norm( csr_matrix.todense(TDM[:,i] - TDM[:,j]),2 ) #GetDistance\n",
    "        \n",
    "# Now compare the distances for different clusters...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
