{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have loaded 100 documents and 4893 words in total!\n"
     ]
    }
   ],
   "source": [
    "#from gensim.corpora.dictionary import Dictionary\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# select the number of documents to parse\n",
    "Subset = 100 #10769\n",
    "filewithTFIDF = \"TFIDF_\"+str(Subset)+\"docs.npy\" # this is used later\n",
    "Distances = np.load(str(Subset)+'New_Doc_Distances.npy')\n",
    "\n",
    "N_Topics = 5\n",
    "\n",
    "FolderToParse = \"BoW_100random/\"#\"BagsOfWords/\"\n",
    "DocList = []\n",
    "for document in os.listdir( FolderToParse ):\n",
    "    # load documents\n",
    "    FileToLoad = FolderToParse + document\n",
    "    f = open(FileToLoad,'rb')\n",
    "    words = f.read().decode('ascii', 'ignore')\n",
    "    f.close()\n",
    "    words = words.split() # tokenize\n",
    "    DocList.append(words)\n",
    "    \n",
    "DocList = DocList[:Subset]\n",
    "# Load the names of species\n",
    "with open('list_of_species.txt', encoding='utf-8', errors='ignore') as f:\n",
    "    Names = f.readlines()\n",
    "Names = [x.strip() for x in Names]\n",
    "\n",
    "# Create dictionary [ID to word]\n",
    "common_dictionary = Dictionary(DocList)\n",
    "# Create text to words mappings & count\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in DocList]\n",
    "print(\"We have loaded {0} documents and {1} words in total!\".format(len(DocList), len(common_dictionary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeDistances(D, C1, C2):\n",
    "    \"\"\"\n",
    "        Function that, given two sets of indices C1, C2 and a matrix D with  \n",
    "        distances calculated for every pair, it computes the average distance.\n",
    "    \"\"\"\n",
    "    S=0\n",
    "    for i in range(len(C1)):\n",
    "        for j in range(len(C2)):\n",
    "            S += D[ C1[i], C2[j] ]\n",
    "    return S/(len(C1)*len(C2))\n",
    "     \n",
    "def EvalClustering(D, Clustering):\n",
    "    \"\"\"\n",
    "        Function that, given a set clusters and a matrix D with distances calculated \n",
    "        for every pair of points, evaluates the accuracy of the partition.\n",
    "        Intra : the average distance for points within one cluster\n",
    "        Inter : the average distance between points from different clusters.\n",
    "    \"\"\"\n",
    "    N_K = len(Clustering)\n",
    "    ClusterDist = np.zeros( (N_K,N_K) )\n",
    "    for c1 in range(N_K):\n",
    "        if len(Clustering[c1])>0:\n",
    "            for c2 in range(c1,N_K):\n",
    "                #first we compute the intra-cluster distance\n",
    "                if len(Clustering[c2])>0:\n",
    "                    ClusterDist[c1,c2] = ComputeDistances(D, list(Clustering[c1]), list(Clustering[c2]))\n",
    "    # evaluate\n",
    "    intra = np.mean(np.diag(ClusterDist))\n",
    "    print('Mean Within-Cluster distance = {0:.3f}.'.format(intra))\n",
    "    inter = np.sum(np.triu(ClusterDist,1))*2/(N_K-1)/N_K\n",
    "    print('Mean Inter-Cluster distance = {0:.3f}.'.format(inter))\n",
    "    return intra, inter, ClusterDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LDA by gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "# Train the model on the corpus.\n",
    "lda = LdaModel(common_corpus, num_topics=N_Topics, alpha='asymmetric', random_state=1)\n",
    "# Now produce probabilities based on the Corpus\n",
    "LDAvectors = []\n",
    "for i in range(len(DocList)):\n",
    "    # first we translate using the dictionary that we have already\n",
    "    temp = [ common_dictionary.doc2bow(text.split()) for text in DocList[i] ]\n",
    "    vector = lda[temp[0]]\n",
    "    LDAvectors.append( vector )\n",
    "print('LDA is complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b. Evaluate - gensim LDA with BW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDAvectors = np.load(\"LDAvectors_gensim_\"+str(Subset)+\".npy\")\n",
    "\n",
    "# Clustering #\n",
    "ClustersLDA = { i:[] for i in range(N_Topics)}# initialize the dictictionary of clusters\n",
    "ClustersNames = { i:[] for i in range(N_Topics)} \n",
    "Labels = []\n",
    "for i in range(len(DocList)):\n",
    "    distr = [ x[1] for x in LDAvectors[i]]\n",
    "    # find the argmax{distr} - ATTENTION: ties ???\n",
    "    label = distr.index(max(distr))\n",
    "    ClustersLDA[label].append(i)\n",
    "    ClustersNames[label].append(Names[i])\n",
    "    Labels.append( label )\n",
    "    \n",
    "# Evaluate\n",
    "t = EvalClustering(Distances, ClustersLDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1c. Evaluate - gensim LDA with KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# load data (again)\n",
    "X =  np.load(\"LDAvectors_gensim_\"+str(Subset)+\".npy\")\n",
    "\n",
    "# possibly needs transform\n",
    "X = np.array([[P[1] for P in Z] for Z in X])\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "\n",
    "km = KMeans(n_clusters=N_Topics, init='k-means++', max_iter=100, n_init=1, random_state=10)\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "km.fit(X)\n",
    "\n",
    "# create the clusters\n",
    "Clusters = { i:[] for i in range(N_Topics)}\n",
    "Labels = list(km.labels_)\n",
    "for i in range(len(DocList)):\n",
    "    Clusters[LabelsKM[i]].append(i)\n",
    "    \n",
    "# Evaluate\n",
    "t = EvalClustering(Distances, Clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LDA by Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 100, n_features: 4893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/dtchome/kalantzisg/.local/lib/python3.4/site-packages/sklearn/decomposition/online_lda.py:314: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "             evaluate_every=-1, learning_decay=0.7,\n",
      "             learning_method='batch', learning_offset=10.0,\n",
      "             max_doc_update_iter=100, max_iter=1000, mean_change_tol=0.001,\n",
      "             n_components=10, n_jobs=None, n_topics=5, perp_tol=0.1,\n",
      "             random_state=2, topic_word_prior=None,\n",
      "             total_samples=1000000.0, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "X = np.load(filewithTFIDF)\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "LDA_SKL = LatentDirichletAllocation(n_topics = N_Topics, max_iter=1000, random_state=2)\n",
    "LDA_SKL.fit(X)\n",
    "print(\"Clustering sparse data with %s\" % LDA_SKL)\n",
    "# get doc-topic distributions\n",
    "LDA_SKLvectors = LDA_SKL.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. Evaluate scikit LDA with BW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering - Black and white approach, as before\n",
    "ClustersSKL = { i:[] for i in range(N_Topics)}\n",
    "LabelsSKL = []\n",
    "for i in range(len(DocList)):\n",
    "    distr = list(LDA_SKLvectors[i])\n",
    "    # find the argmax{distr} - ATTENTION: ties ???\n",
    "    label = distr.index(max(distr))\n",
    "    ClustersSKL[label].append(i)\n",
    "    LabelsSKL.append( label )\n",
    "    \n",
    "# Evaluate\n",
    "t = EvalClustering(Distances, ClustersSKL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2c. Evaluate scikit LDA with K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = LDA_SKLvectors\n",
    "\n",
    "km = KMeans(n_clusters=N_Topics, init='k-means++', max_iter=100, n_init=1, random_state=10)\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "km.fit(X)\n",
    "\n",
    "# create the clusters\n",
    "Clusters = { i:[] for i in range(N_Topics)}\n",
    "Labels = list(km.labels_)\n",
    "for i in range(len(DocList)):\n",
    "    Clusters[LabelsKM[i]].append(i)\n",
    "    \n",
    "# Evaluate\n",
    "t = EvalClustering(Distances, Clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Benchmark technique: K-Means on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X =  np.load(filewithTFIDF)\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "km = KMeans(n_clusters=N_Topics, init='k-means++', max_iter=100, n_init=1, random_state=10)\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "km.fit(X)\n",
    "\n",
    "# create the clusters\n",
    "ClustersKM = { i:[] for i in range(N_Topics)}\n",
    "LabelsKM = list(km.labels_)\n",
    "for i in range(len(DocList)):\n",
    "    ClustersKM[LabelsKM[i]].append(i)\n",
    "    \n",
    "# Evaluate\n",
    "t = EvalClustering(Distances, ClustersKM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b. Advanced approach: SVD + K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# Dimensionality reduction\n",
    "svd = TruncatedSVD(50)\n",
    "# we use the same X as before\n",
    "X = svd.fit_transform(X)\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "km = KMeans(n_clusters=N_Topics, init='k-means++', max_iter=100, n_init=1, random_state=10)\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "km.fit(X)\n",
    "\n",
    "# create the clusters\n",
    "ClustersKM = { i:[] for i in range(N_Topics)}\n",
    "LabelsKM = list(km.labels_)\n",
    "for i in range(len(DocList)):\n",
    "    ClustersKM[LabelsKM[i]].append(i)\n",
    "    \n",
    "# Evaluate\n",
    "t = EvalClustering(Distances, ClustersKM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Our LDA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the big loop...\n",
      "More than 1.0 % is completed! Rate = 7.754592418670654\n",
      "More than 11.0 % is completed! Rate = 4.198843869295987\n",
      "More than 21.0 % is completed! Rate = 4.0200606641315275\n",
      "More than 31.0 % is completed! Rate = 3.9916513043065227\n",
      "More than 41.0 % is completed! Rate = 4.006635694968991\n",
      "More than 51.0 % is completed! Rate = 3.9947992773617016\n",
      "More than 61.0 % is completed! Rate = 3.9865652029631566\n",
      "More than 71.0 % is completed! Rate = 3.9873329552126604\n",
      "More than 81.0 % is completed! Rate = 3.993535477438091\n",
      "More than 91.0 % is completed! Rate = 3.9916497822646257\n",
      "LDA is complete! Total time = 395.5250279903412\n"
     ]
    }
   ],
   "source": [
    "# Implement LDA\n",
    "# Number matrix (Replacing words in documents with word IDs)\n",
    "from time import time\n",
    "N_K = 5 # N_Topics # set the number of topics\n",
    "N_D = len(DocList)\n",
    "corpus=np.unique(np.concatenate(DocList),axis=0)\n",
    "N_W = corpus.shape[0] # words in the vocabulary\n",
    "\n",
    "# SELECT #iterations\n",
    "T=100\n",
    "\n",
    "X_number = np.copy(DocList)\n",
    "for doc_number in range(X_number.shape[0]):\n",
    "    for doc_length in range(len(X_number[doc_number])):\n",
    "        X_number[doc_number][doc_length]=  np.where(corpus==X_number[doc_number][doc_length])[0][0]\n",
    "        \n",
    "# Dirichlet priors\n",
    "alpha = 1 # Choice of alpha affects document clustering \n",
    "gamma = 1\n",
    "\n",
    "#Z = np.copy(X_number)\n",
    "#for doc_number in range(Z.shape[0]):\n",
    "#    for doc_length in range(len(Z[doc_number])):\n",
    "#        Z[doc_number][doc_length]= np.random.randint(N_K)\n",
    "        \n",
    "Z = []#[np.array(N_D, dtype=object)]\n",
    "for doc in range(N_D):\n",
    "    Z.append( np.random.randint(N_K, size=len(DocList[doc])) )\n",
    "        \n",
    "# Pi := document topic distribution\n",
    "Pi = np.zeros([N_D, N_K])\n",
    "for i in range(N_D):\n",
    "    Pi[i] = np.random.dirichlet(alpha*np.ones(N_K))\n",
    "\n",
    "A = Pi\n",
    "#print(A)\n",
    "\n",
    "# B := word topic distribution\n",
    "B = np.zeros([N_K, N_W])\n",
    "for k in range(N_K):\n",
    "    B[k] = np.random.dirichlet(gamma*np.ones(N_W))\n",
    "t0 = time()    \n",
    "print(\"Starting the big loop...\")    \n",
    "for iterations in range(T):  #Need at least 1000 iterations for Gibbs sampling to work!\n",
    "\n",
    "    # Updating Z matrix\n",
    "    for doc_number in range(N_D):     \n",
    "        for doc_length in range(len(Z[doc_number])):     \n",
    "            # Calculate params for Z\n",
    "            p_iv = np.exp(np.log(Pi[doc_number]) + np.log( B[:, X_number[doc_number][ doc_length]] ))\n",
    "            p_iv /= np.sum(p_iv)\n",
    "\n",
    "             # Resample word topic assignment Z\n",
    "            Z[doc_number][doc_length] = np.random.multinomial(1, p_iv).argmax()\n",
    "    # Updating Pi   \n",
    "    for i in range(N_D):\n",
    "        # Gather sufficient statistics\n",
    "        ###m = np.zeros(N_K)\n",
    "        ###for k in range(N_K):\n",
    "        ###    m[k] = np.sum(Z[i] == k)\n",
    "        \n",
    "        m = np.array( [np.sum(Z[i] == k) for k in range(N_K)] )\n",
    "        # Resample doc topic dist.\n",
    "        Pi[i, :] = np.random.dirichlet(alpha + m)\n",
    "        \n",
    "    #Updating B\n",
    "    for k in range(N_K):\n",
    "        #print(k)\n",
    "        n = np.zeros(N_W) \n",
    "    \n",
    "        #Gather statistics       \n",
    "        for v in range(N_W):\n",
    "            for doc_number in range(N_D):\n",
    "                n[v] = len([ x for x in np.where(X_number[doc_number] == v) if Z[doc_number][x] ==k ])\n",
    "                ###for doc_length in range(len(Z[doc_number])):\n",
    "                ###    n[v] += (X_number[doc_number][ doc_length]==v) and (Z[doc_number][doc_length] ==k)\n",
    "        \n",
    "        # Resample word topic distribution\n",
    "        B[k,:] = np.random.dirichlet(gamma+n)\n",
    "    #progress check\n",
    "    if (iterations-1)%10==0:\n",
    "        print(\"More than {0} % is completed! Rate = {1}\".format(100*iterations/T, (time()-t0)/iterations))\n",
    "print('LDA is complete! Total time = {0}'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1041913 ,  0.57478023,  0.06239164,  0.05222822,  0.04492622,\n",
       "         0.03942166,  0.03511779,  0.03166205,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10418669,  0.57478482,  0.06239164,  0.05222822,  0.04492621,\n",
       "         0.03942166,  0.03511779,  0.03166205,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10364865,  0.57532203,  0.06238137,  0.05223848,  0.04492728,\n",
       "         0.03942145,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10364801,  0.57532275,  0.06238137,  0.05223848,  0.04492728,\n",
       "         0.03942145,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10369829,  0.57527232,  0.06238145,  0.05223851,  0.04492728,\n",
       "         0.03942146,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10425949,  0.57471192,  0.06239174,  0.05222824,  0.04492622,\n",
       "         0.03942166,  0.03511779,  0.03166205,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60139871,  0.07765351,  0.06232877,  0.05221418,  0.04492401,\n",
       "         0.0394202 ,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10365877,  0.57531172,  0.06238139,  0.05223866,  0.04492728,\n",
       "         0.03942145,  0.03511775,  0.03166203,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10363884,  0.57533187,  0.06238135,  0.05223846,  0.04492727,\n",
       "         0.03942145,  0.03511775,  0.03166203,  0.0288255 ,  0.02645542],\n",
       "       [ 0.1056209 ,  0.07781462,  0.06232883,  0.05221893,  0.04492506,\n",
       "         0.03942047,  0.03511773,  0.03166203,  0.0288255 ,  0.52206594],\n",
       "       [ 0.10384361,  0.57512665,  0.06238164,  0.05223864,  0.0449273 ,\n",
       "         0.03942146,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60136998,  0.07767598,  0.06233223,  0.05221542,  0.04492508,\n",
       "         0.03942059,  0.03511777,  0.03166202,  0.0288255 ,  0.02645542],\n",
       "       [ 0.1019226 ,  0.57710463,  0.06233409,  0.05222879,  0.0449277 ,\n",
       "         0.0394215 ,  0.03511771,  0.03166202,  0.0288255 ,  0.02645542],\n",
       "       [ 0.60170889,  0.0773395 ,  0.06233262,  0.05221418,  0.04492401,\n",
       "         0.03942015,  0.03511771,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60083616,  0.07815374,  0.06237508,  0.05222683,  0.04492585,\n",
       "         0.03942124,  0.03511806,  0.03166207,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10369349,  0.57527709,  0.06238145,  0.05223854,  0.04492728,\n",
       "         0.03942146,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10455976,  0.57442206,  0.06237696,  0.0522309 ,  0.04492757,\n",
       "         0.03942172,  0.03511802,  0.03166207,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10203469,  0.0774772 ,  0.06238818,  0.05221543,  0.54440367,\n",
       "         0.03942017,  0.03511772,  0.03166206,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10252217,  0.07767898,  0.0623483 ,  0.05221666,  0.54375273,\n",
       "         0.03942046,  0.03511775,  0.03166202,  0.02882551,  0.02645543],\n",
       "       [ 0.601515  ,  0.07750084,  0.06235743,  0.0522209 ,  0.04492404,\n",
       "         0.03942108,  0.03511774,  0.03166204,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10365026,  0.57532048,  0.06238137,  0.05223848,  0.04492728,\n",
       "         0.03942145,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10416633,  0.5748052 ,  0.0623916 ,  0.05222821,  0.04492621,\n",
       "         0.03942165,  0.03511778,  0.03166205,  0.0288255 ,  0.02645542],\n",
       "       [ 0.60095543,  0.07805732,  0.06235437,  0.05222387,  0.04492715,\n",
       "         0.03942113,  0.03511778,  0.03166205,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10454092,  0.5744409 ,  0.06237695,  0.05223089,  0.04492757,\n",
       "         0.03942172,  0.03511802,  0.03166207,  0.0288255 ,  0.02645542],\n",
       "       [ 0.60165566,  0.07738797,  0.06232879,  0.0522224 ,  0.04492402,\n",
       "         0.03942048,  0.03511771,  0.03166202,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10369489,  0.07730779,  0.06232875,  0.05221561,  0.04492401,\n",
       "         0.03942015,  0.03511771,  0.03166202,  0.0288255 ,  0.52450359],\n",
       "       [ 0.60172248,  0.0773292 ,  0.06232876,  0.05221417,  0.04492401,\n",
       "         0.03942073,  0.03511771,  0.03166202,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10387049,  0.57509905,  0.06238176,  0.05223916,  0.0449273 ,\n",
       "         0.03942154,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60096943,  0.07797113,  0.06241675,  0.05223164,  0.04492842,\n",
       "         0.03942173,  0.03511792,  0.03166207,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10368324,  0.07768015,  0.06235992,  0.05221615,  0.04492403,\n",
       "         0.03942088,  0.53277272,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10620622,  0.57278675,  0.06236719,  0.05223043,  0.04492703,\n",
       "         0.03942147,  0.0351179 ,  0.03166204,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10377643,  0.57519317,  0.0623816 ,  0.05223938,  0.04492729,\n",
       "         0.03942146,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60103613,  0.07787036,  0.06245279,  0.05223028,  0.04492747,\n",
       "         0.03942223,  0.03511779,  0.03166205,  0.02882551,  0.02645543],\n",
       "       [ 0.10364681,  0.57532394,  0.06238137,  0.05223849,  0.04492728,\n",
       "         0.03942145,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10367528,  0.57529539,  0.06238141,  0.05223849,  0.04492728,\n",
       "         0.03942145,  0.03511775,  0.03166203,  0.0288255 ,  0.02645542],\n",
       "       [ 0.60144299,  0.0775819 ,  0.06234693,  0.05221669,  0.0449299 ,\n",
       "         0.03942078,  0.03511786,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10344238,  0.07734305,  0.56059545,  0.05221418,  0.04492401,\n",
       "         0.0394203 ,  0.03511771,  0.03166202,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10284109,  0.07737241,  0.06233155,  0.05221459,  0.54375839,\n",
       "         0.03942134,  0.03511773,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10192216,  0.5771054 ,  0.06233409,  0.05222877,  0.0449277 ,\n",
       "         0.03942126,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10235832,  0.07732119,  0.06232874,  0.55158645,  0.04492401,\n",
       "         0.03942066,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60153031,  0.07750136,  0.06234211,  0.05222034,  0.04492404,\n",
       "         0.03942107,  0.03511779,  0.03166202,  0.0288255 ,  0.02645542],\n",
       "       [ 0.60103923,  0.07786746,  0.06245266,  0.05223027,  0.04492747,\n",
       "         0.03942218,  0.03511779,  0.03166205,  0.02882551,  0.02645543],\n",
       "       [ 0.10235664,  0.07732119,  0.06232874,  0.55158812,  0.04492401,\n",
       "         0.03942066,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10192217,  0.5771054 ,  0.06233409,  0.05222877,  0.0449277 ,\n",
       "         0.03942126,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.6009078 ,  0.07804174,  0.06241154,  0.05223056,  0.04492637,\n",
       "         0.03942114,  0.03511787,  0.03166205,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10371295,  0.57525754,  0.06238148,  0.05223853,  0.04492728,\n",
       "         0.03942146,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10440115,  0.57458091,  0.06237683,  0.05223086,  0.04492756,\n",
       "         0.03942172,  0.03511803,  0.03166207,  0.02882551,  0.02645543],\n",
       "       [ 0.10420638,  0.57476509,  0.06239165,  0.05222822,  0.04492621,\n",
       "         0.03942165,  0.03511778,  0.03166205,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10367201,  0.57529867,  0.0623814 ,  0.05223849,  0.04492728,\n",
       "         0.03942145,  0.03511775,  0.03166203,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10434503,  0.57462621,  0.06239183,  0.05222826,  0.04492622,\n",
       "         0.03942166,  0.03511778,  0.03166205,  0.0288255 ,  0.02645542],\n",
       "       [ 0.6014179 ,  0.07759636,  0.06235733,  0.05222058,  0.04492679,\n",
       "         0.03942034,  0.03511772,  0.03166209,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10366742,  0.57530326,  0.06238139,  0.05223848,  0.04492728,\n",
       "         0.03942145,  0.03511775,  0.03166203,  0.0288255 ,  0.02645542],\n",
       "       [ 0.6007995 ,  0.07814961,  0.06241189,  0.05223062,  0.04492638,\n",
       "         0.03942114,  0.03511787,  0.03166205,  0.0288255 ,  0.02645542],\n",
       "       [ 0.1036548 ,  0.57531589,  0.06238137,  0.05223849,  0.04492728,\n",
       "         0.03942145,  0.03511775,  0.03166203,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10192373,  0.57710224,  0.06233412,  0.05222913,  0.04492776,\n",
       "         0.03942236,  0.03511771,  0.03166202,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10235822,  0.07732119,  0.06232874,  0.55158651,  0.04492401,\n",
       "         0.03942067,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60103834,  0.07786842,  0.06245263,  0.05223027,  0.04492747,\n",
       "         0.03942215,  0.03511779,  0.03166205,  0.02882551,  0.02645543],\n",
       "       [ 0.10187515,  0.07743625,  0.06232876,  0.05222233,  0.04492402,\n",
       "         0.53915286,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60139859,  0.07759428,  0.06236588,  0.05223162,  0.04492631,\n",
       "         0.03942262,  0.03511779,  0.03166204,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60156322,  0.07748878,  0.06232881,  0.05221422,  0.04492416,\n",
       "         0.03942018,  0.03511772,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10283682,  0.07737235,  0.06233154,  0.05221457,  0.54376274,\n",
       "         0.03942131,  0.03511772,  0.03166202,  0.0288255 ,  0.02645542],\n",
       "       [ 0.60103518,  0.07787044,  0.06245306,  0.05223031,  0.04492748,\n",
       "         0.03942281,  0.03511779,  0.03166205,  0.02882551,  0.02645543],\n",
       "       [ 0.10190775,  0.57714206,  0.06232875,  0.05221616,  0.04492448,\n",
       "         0.03942017,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10369976,  0.57527083,  0.06238144,  0.05223851,  0.04492728,\n",
       "         0.03942145,  0.03511775,  0.03166203,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10381196,  0.57515836,  0.06238163,  0.05223861,  0.04492729,\n",
       "         0.03942147,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60136706,  0.07761696,  0.06238784,  0.05222121,  0.04492556,\n",
       "         0.03942065,  0.03511773,  0.03166206,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10302726,  0.57602149,  0.0623298 ,  0.0522166 ,  0.04492401,\n",
       "         0.03942015,  0.03511773,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60103816,  0.07786856,  0.06245263,  0.05223026,  0.04492747,\n",
       "         0.03942216,  0.03511779,  0.03166205,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10174902,  0.07730343,  0.06232874,  0.55221403,  0.04492401,\n",
       "         0.03942015,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10175148,  0.57728624,  0.06234223,  0.05221509,  0.04492401,\n",
       "         0.03942026,  0.03511771,  0.03166202,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10379854,  0.57517159,  0.06238161,  0.05223884,  0.04492729,\n",
       "         0.03942146,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60088086,  0.07806858,  0.06241163,  0.05223057,  0.04492637,\n",
       "         0.03942114,  0.03511787,  0.03166205,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10236333,  0.0773212 ,  0.06232874,  0.55158138,  0.04492401,\n",
       "         0.03942067,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60103971,  0.07786704,  0.06245262,  0.05223027,  0.04492747,\n",
       "         0.03942216,  0.03511779,  0.03166205,  0.02882551,  0.02645543],\n",
       "       [ 0.10187446,  0.07743546,  0.06232876,  0.05222228,  0.04492402,\n",
       "         0.53915441,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10367049,  0.5753001 ,  0.06238142,  0.05223851,  0.04492728,\n",
       "         0.03942147,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10386445,  0.57510442,  0.06238173,  0.05223991,  0.0449273 ,\n",
       "         0.03942146,  0.03511775,  0.03166203,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10386509,  0.5751307 ,  0.06237938,  0.05221448,  0.04492941,\n",
       "         0.03942029,  0.03511771,  0.03166205,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60133904,  0.07762724,  0.06240537,  0.0522224 ,  0.04492459,\n",
       "         0.03942065,  0.03511773,  0.03166205,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60106844,  0.07797609,  0.06232886,  0.0522201 ,  0.04492532,\n",
       "         0.03942055,  0.03511774,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.1043179 ,  0.57465607,  0.06238382,  0.05223469,  0.04492588,\n",
       "         0.03942087,  0.03511782,  0.03166204,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60133535,  0.07769918,  0.06233628,  0.05221978,  0.04492773,\n",
       "         0.03942075,  0.03511802,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10365198,  0.57531875,  0.06238137,  0.05223847,  0.04492727,\n",
       "         0.03942145,  0.03511775,  0.03166203,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10174938,  0.07730349,  0.06232877,  0.55221176,  0.04492401,\n",
       "         0.0394219 ,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10432282,  0.57465935,  0.06237675,  0.05223083,  0.04492756,\n",
       "         0.03942172,  0.03511803,  0.03166207,  0.02882551,  0.02645543],\n",
       "       [ 0.60158944,  0.07739256,  0.06239204,  0.0522203 ,  0.04492428,\n",
       "         0.0394207 ,  0.03511774,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10174911,  0.57730317,  0.06232875,  0.05221418,  0.04492401,\n",
       "         0.03942015,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10367932,  0.57529128,  0.06238142,  0.0522385 ,  0.04492728,\n",
       "         0.03942146,  0.03511776,  0.03166203,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10383548,  0.57513475,  0.06238165,  0.0522386 ,  0.04492729,\n",
       "         0.03942148,  0.03511775,  0.03166203,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10174903,  0.07730343,  0.06232874,  0.55221397,  0.04492401,\n",
       "         0.03942015,  0.03511771,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.6013869 ,  0.07762477,  0.06234561,  0.05222935,  0.04493089,\n",
       "         0.03942173,  0.03511778,  0.03166204,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10178466,  0.57719594,  0.06239456,  0.05221663,  0.04492654,\n",
       "         0.03942103,  0.03511772,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10368259,  0.575288  ,  0.06238141,  0.05223852,  0.04492728,\n",
       "         0.03942145,  0.03511775,  0.03166203,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10367379,  0.57529682,  0.06238141,  0.05223854,  0.04492728,\n",
       "         0.03942145,  0.03511775,  0.03166203,  0.0288255 ,  0.02645542],\n",
       "       [ 0.10380105,  0.07730971,  0.062383  ,  0.05221419,  0.04492554,\n",
       "         0.03942058,  0.03511771,  0.03166202,  0.0288255 ,  0.52434075],\n",
       "       [ 0.10192218,  0.57710534,  0.06233408,  0.05222876,  0.04492769,\n",
       "         0.03942126,  0.03511771,  0.03166202,  0.0288255 ,  0.02645542],\n",
       "       [ 0.60158324,  0.07739297,  0.06239773,  0.05222033,  0.04492428,\n",
       "         0.03942078,  0.03511774,  0.03166202,  0.0288255 ,  0.02645543],\n",
       "       [ 0.60140163,  0.07759238,  0.06236572,  0.05223155,  0.0449263 ,\n",
       "         0.03942169,  0.03511779,  0.03166204,  0.0288255 ,  0.02645543],\n",
       "       [ 0.1042796 ,  0.57469177,  0.06239176,  0.05222825,  0.04492622,\n",
       "         0.03942166,  0.03511779,  0.03166205,  0.0288255 ,  0.02645543],\n",
       "       [ 0.10439666,  0.57457447,  0.06239192,  0.05222828,  0.04492623,\n",
       "         0.03942167,  0.03511779,  0.03166205,  0.0288255 ,  0.02645543]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. Our LDA with BW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering #\n",
    "ClustersOUR = { i:[] for i in range(N_Topics)}# initialize the dictictionary of clusters\n",
    "for i in range(len(DocList)):\n",
    "    #distr = [ x[1] for x in Pi[i]]\n",
    "    # find the argmax{distr} - ATTENTION: ties ???\n",
    "    label = np.argmax(Pi[i])\n",
    "    ClustersOUR[label].append(i)\n",
    "    \n",
    "# Evaluate\n",
    "t = EvalClustering(Distances, ClustersOUR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4c. Our LDA with KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create doc-word list of lists\n",
    "\"\"\"\n",
    "corpus=np.unique(np.concatenate(DocList))\n",
    "TDM = np.zeros((len(common_dictionary),N_D)) # we start by a full matrix and then transform it\n",
    "for doc in range(N_D):\n",
    "    temp = np.unique( DocList[doc] ) # get the different words on this document\n",
    "    #temp2 = np.zeros((N_V,1))\n",
    "    for i in range( len(temp) ):\n",
    "        word = temp[i]\n",
    "        count = len([ x for x in DocList[doc] if x == word])\n",
    "        # we must get the index of this word in the (total) corpus\n",
    "        TDM[ np.where(corpus == word) , doc] = count\n",
    "\n",
    "# sanity check\n",
    "for doc in range(N_D):\n",
    "    if sum(TDM[:,doc])!=len(DocList[doc]):\n",
    "        print(\"Doc-{0} has a problem!\".format(doc))\n",
    "  \n",
    "TDM = np.transpose(TDM)\n",
    "\"\"\"\n",
    "#print(\"n_samples: %d, n_features: %d\" % TDM.shape)\n",
    "#LDA_SKL = LatentDirichletAllocation(n_topics = 100, max_iter=50, random_state=1)\n",
    "#LDA_SKL.fit( TDM )\n",
    "# get doc-topic distributions\n",
    "#LDA_SKLvectors = LDA_SKL.transform(TDM)\n",
    "km = KMeans(n_clusters=3, init='k-means++', max_iter=100, n_init=1, random_state=1)\n",
    "print(\"Clustering LDA data with %s\" % km)\n",
    "km.fit(LDA_SKLvectors)\n",
    "\n",
    "# create the clusters\n",
    "ClustersXX = { i:[] for i in range(N_Topics)}\n",
    "LabelsXX = list(km.labels_)\n",
    "for i in range(len(DocList)):\n",
    "    ClustersXX[LabelsXX[i]].append(i)\n",
    "    \n",
    "# Evaluate\n",
    "t = EvalClustering(Distances, ClustersXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Clustering with random assigning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClustersRAND = { i:[] for i in range(N_Topics)}# initialize the dictictionary of clusters\n",
    "for i in range(len(DocList)):\n",
    "    #distr = [ x[1] for x in Pi[i]]\n",
    "    # find the argmax{distr} - ATTENTION: ties ???\n",
    "    label = np.random.randint(N_Topics)\n",
    "    ClustersRAND[label].append(i)\n",
    "    \n",
    "# Evaluate\n",
    "t = EvalClustering(Distances, ClustersRAND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of LDA output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KLdivergence(P,Q):\n",
    "    #import numpy as np\n",
    "    n = P.shape[0]\n",
    "    total = []\n",
    "    for subject in range(n):\n",
    "        D = 0\n",
    "        for x in range(P.shape[1]):\n",
    "            D +=P[subject][x]*np.log( P[subject][x]/Q[subject][x] )\n",
    "        total.append(D)\n",
    "    return total #np.mean(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.5995593 ,  3.81734874,  3.81734874],\n",
       "       [ 0.55178462,  0.        ,  3.92596919,  3.92596919],\n",
       "       [ 1.71809235,  1.99350227,  0.        ,  0.        ],\n",
       "       [ 1.71809235,  1.99350227,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDAour1 = Pi\n",
    "LDAour2 = np.load(\"prob100it5topcristiana.npy\")\n",
    "#LDAskl1 = LDA_SKLvectors\n",
    "LDAskl2 = LDA_SKLvectors\n",
    "\n",
    "compare = [LDAour1, LDAour2, LDAskl1, LDAskl2]\n",
    "\n",
    "DL_All = np.zeros((len(compare), len(compare)))\n",
    "for i in range(len(compare)):\n",
    "    for j in range(len(compare)):\n",
    "        DL_All[i,j] = np.mean( KLdivergence(compare[i], compare[j]) )\n",
    "DL_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('DifferentLDAs.npy',compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8332762475876307,\n",
       " 0.46417857818970443,\n",
       " 0.49493944643137322,\n",
       " 0.85725336640298355,\n",
       " 2.0271776301668285,\n",
       " 1.619456610414258,\n",
       " 1.1390552004718135,\n",
       " 1.1413990591956116,\n",
       " 1.2523371176183093,\n",
       " 1.3786597738381747,\n",
       " 1.6651537017824045,\n",
       " 2.0357819173612142,\n",
       " 2.3227806576543037,\n",
       " 1.413728245379569,\n",
       " 1.1611388888170446,\n",
       " 0.86955534820706182,\n",
       " 1.5020122342098325,\n",
       " 1.2934847461970278,\n",
       " 1.3182752929474022,\n",
       " 0.57924430728592835,\n",
       " 1.6010915450205356,\n",
       " 1.9549962297865895,\n",
       " 1.5453323581689897,\n",
       " 1.8846794253183872,\n",
       " 0.82564885644874286,\n",
       " 1.3335109102244529,\n",
       " 3.2628100941175311,\n",
       " 1.3204776509283704,\n",
       " 1.2920303069752137,\n",
       " 1.8250591354348302,\n",
       " 1.755659665133551,\n",
       " 0.67097760764485415,\n",
       " 1.5255246438807981,\n",
       " 0.94559553906258664,\n",
       " 2.035798880377814,\n",
       " 1.93839957561961,\n",
       " 1.3180543046664752,\n",
       " 1.3337994950828289,\n",
       " 1.8535247565324635,\n",
       " 2.1439874793996339,\n",
       " 1.5392526859334792,\n",
       " 1.3115418795763192,\n",
       " 1.9605764363122764,\n",
       " 3.339047979258229,\n",
       " 1.5133244832575494,\n",
       " 1.2943547395562074,\n",
       " 1.4119664892660262,\n",
       " 0.9814803075271703,\n",
       " 2.3563650152993572,\n",
       " 2.1735194337598642,\n",
       " 1.7145057012363774,\n",
       " 3.2444803149738801,\n",
       " 1.7519033105654418,\n",
       " 1.4631327313261528,\n",
       " 2.7224129676889879,\n",
       " 0.97660189499887351,\n",
       " 1.258257920600935,\n",
       " 2.286713747701127,\n",
       " 1.5993879674796703,\n",
       " 1.9810883372319423,\n",
       " 1.3956264428784855,\n",
       " 1.3615252894511602,\n",
       " 2.1414700421813975,\n",
       " 2.1681346526427134,\n",
       " 0.88407963813389379,\n",
       " 1.3951215484909572,\n",
       " 0.94450660146506937,\n",
       " 1.8241750725474237,\n",
       " 0.59485905348053725,\n",
       " 2.5139749957823567,\n",
       " 1.0284946717144019,\n",
       " 1.3609175718900122,\n",
       " 1.8702195952054788,\n",
       " 1.4571499591005956,\n",
       " 1.0410241579902508,\n",
       " 1.5707736563799695,\n",
       " 0.56353113447961345,\n",
       " 1.6176183868033267,\n",
       " 1.7591876775694812,\n",
       " 1.4424196053827394,\n",
       " 3.5718791626876762,\n",
       " 1.3382563868788429,\n",
       " 1.4433423490713599,\n",
       " 1.4923729889320929,\n",
       " 1.5549624036496057,\n",
       " 1.8641088039058769,\n",
       " 3.7269742199090206,\n",
       " 1.0839301323575767,\n",
       " 2.8653235834807926,\n",
       " 1.3260049848232895,\n",
       " 3.3574010731320834,\n",
       " 1.3731272973946389,\n",
       " 4.6333674702894854,\n",
       " 6.8520904971164445,\n",
       " 1.5258476231996443,\n",
       " 2.5468500914228649,\n",
       " 1.679690395505828,\n",
       " 1.7790129614603065,\n",
       " 1.6687988068012669,\n",
       " 1.5753229509826183]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KLdivergence( LDAskl1, LDAour1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
